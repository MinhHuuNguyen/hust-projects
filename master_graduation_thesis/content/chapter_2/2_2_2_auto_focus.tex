\def\focusbranch{
    Nhánh focus \index{nhánh focus} của RetinaFocus được xây dựng dựa trên mô hình AutoFocus \cite{najibi2019autofocus}, một mô hình giải quyết bài toán xử lý ảnh chất lượng cao rất hiệu quả.
    Ý tưởng của AutoFocus \cite{najibi2019autofocus} hướng đến việc loại bỏ những pixels \index{pixels} dư thừa mà mô hình phải xử lý trong quá trình dự đoán nhưng vẫn giữ được ý tưởng về việc sử dụng Image Pyramids.
    Ý tưởng của nhánh Focus \index{nhánh focus} được thiết kế nhằm dự đoán những khu vực đáng chú ý ở trên ảnh và loại bỏ những khu vực khả năng cao không chứa đối tượng ở những kích thước ảnh lớn hơn, từ đó, tiết kiệm được rất nhiều chi phí tính toán trong quá trình dự đoán của mô hình.

    \noindent
    Dựa trên mô hình AutoFocus \cite{najibi2019autofocus}, nhánh Focus \index{nhánh focus} của RetinaFocus gồm hai thành phần là \textit{Thuật toán Focus Pixel} và \textit{Thuật toán sinh Focus Chips}.
    Ngoài ra, bổ sung thêm \textit{Thuật toán Focus Stacking} vào nhánh Detection \index{nhánh Detection}.

    \noindent
    \textbf{\textit{Thuật toán Focus Pixel}} \\
    Tương tự như trong mô hình AutoFocus \cite{najibi2019autofocus}, thuật toán Focus Pixel là thuật toán giúp chúng ta có thể xác định được vị trí khu vực có khả năng chứa đối tượng và cần zoom trên ảnh.
    Ý tưởng của thuật toán Focus Pixel  dựa trên việc khi ta đưa đầu vào một ảnh có kích thước $X \times Y$ qua một khối Conv, feature maps \index{feature maps} mà ta thu được có kích thước $X' \times Y'$, trong đó: $X' = \lceil \frac{X}{s} \rceil$, $Y' = \lceil \frac{Y}{s} \rceil$, và $s$ là stride của cả khối Conv.
    Từ đó ta có thể ngầm hiểu rằng một pixels \index{pixels} trên feature maps \index{feature maps} có kích thước $X' \times Y'$ đại diện cho một khu vực có kích thước $s \times s$ trên ảnh đầu vào. \\
    Cụ thể, Focus Pixel  xác định các pixels \index{pixels} trên mask là các \textit{pixels cần được focus} nếu như pixels \index{pixels} đó có overlap với grountruth bounding box \index{bounding box} của đối tượng có kích thước nhỏ.
    Tiếp theo, các pixels \index{pixels} trên mask là các \textit{pixels không cần quan tâm} nếu như pixels \index{pixels} đó có overlap với groundtruth \index{groundtruth} bounding box \index{bounding box} của đối tượng có kích thước lớn hoặc rất nhỏ.
    Cuối cùng, các \textit{pixels \index{pixels} không cần được focus} trên mask là các pixels \index{pixels} còn lại.

    \[l = 
        \begin{cases}
            1, & IoU \index{IoU}(GT, l) > 0, a < \sqrt{GTArea} < b \\
            -1, & IoU \index{IoU}(GT, l) > 0, \sqrt{GTArea} < a  \\
            -1, & IoU \index{IoU}(GT, l) > 0, b < \sqrt{GTArea} < c  \\
            0, & \text{otherwise}
        \end{cases}
    \]

    \noindent
    trong đó: \\
    - $IoU \index{IoU}(GT, l)$ là chỉ số IoU \index{IoU} giữa khu vực $s \times s$ và groundtruth \index{groundtruth} bounding box \index{bounding box} của đối tượng trên ảnh đầu vào. \\
    - $GTArea$ là diện tích của groundtruth \index{groundtruth} bounding box \index{bounding box} của đối tượng trên ảnh đầu vào. \\
    Nếu một khu vực $s \times s$ overlap với nhiều groundtruth \index{groundtruth} bounding box \index{bounding box} của đối tượng, thì pixels \index{pixels} đó được ưu tiên là một Focus Pixel .

    \noindent
    Trong các thí nghiệm mà nhóm tác giả của AutoFocus \cite{najibi2019autofocus} thực hiện, nhóm tác giả sử dụng các tham số $a = 5, b = 64, c = 90$ nghĩa là các groundtruth \index{groundtruth} bounding box \index{bounding box} có kích thước từ $5 \times 5$ đến $64 \times 64$ là các bounding box \index{bounding box} cần được focus, các groundtruth \index{groundtruth} bounding box \index{bounding box} có kích thước dưới $5 \times 5$ hoặc từ $64 \times 64$ đến $90 \times 90$ là các bounding box \index{bounding box} không cần quan tâm và các groundtruth \index{groundtruth} bounding box \index{bounding box} có kích thước trên $90 \times 90$ là các bounding box \index{bounding box} không cần được focus.

    \noindent
    Tuy nhiên, để nhánh Focus hoạt động hiệu quả, ta cần xây dựng được bộ tham số phù hợp với bộ dữ liệu và nhánh Detection \index{nhánh Detection}.
    Để xây dựng được bộ tham số này, ta cần phân tích điểm yếu của nhánh Detection \index{nhánh Detection} trên bộ dữ liệu WIDER FACE.
    Từ những điểm yếu, ta lựa chọn bộ tham số của nhánh Focus \index{nhánh Focus} nhằm giúp cho nhánh Focus \index{nhánh Focus} xác định được những vùng mà nhánh Detection \index{nhánh Detection} dự đoán yếu và zoom in giúp nhánh Detection \index{nhánh Detection} dự đoán chính xác hơn.

    \begin{figure}[H]
        \centering
        \subfigure[]{\includegraphics[width=0.32\textwidth, trim={2.3cm 2.3cm 2.3cm 2.3cm}, clip]{images/retinafocus_iou_50_compare_percent}} 
        \subfigure[]{\includegraphics[width=0.32\textwidth, trim={2.3cm 2.3cm 2.3cm 2.3cm}, clip]{images/retinafocus_iou_75_compare_percent}} 
        \subfigure[]{\includegraphics[width=0.32\textwidth, trim={2.3cm 2.3cm 2.3cm 2.3cm}, clip]{images/retinafocus_iou_90_compare_percent}} 
        \caption{Tỷ lệ số lượng bounding box \index{bounding box} mà mô hình RetinaFace dự đoán ra và không dự đoán ra tương ứng với IoU \index{IoU} 0.5 (a), IoU \index{IoU} 0.75 (b), IoU \index{IoU} 0.9 (c)}
        \label{fig:retinafocus_iou_compare_percent}
    \end{figure}

    \noindent
    Trong hình \ref{fig:retinafocus_iou_compare_percent}, trên cả ba mức IoU \index{IoU}, tỷ lệ số lượng bounding box \index{bounding box} mà mô hình RetinaFace không dự đoán ra đối với nhóm các bounding box \index{bounding box} nhỏ từ 0 pixels \index{pixels} đến 30 pixels \index{pixels} và đặc biệt là từ 0 pixels \index{pixels} đến 10 pixels \index{pixels} đều cao vượt trội so với các kích thước bounding box \index{bounding box} khác.

    \begin{figure}[H]
        \centering
        \subfigure[]{\includegraphics[width=0.32\textwidth, trim={5cm 4.7cm 4.3cm 4.6cm}, clip]{images/retinafocus_iou_50_lower}} 
        \subfigure[]{\includegraphics[width=0.32\textwidth, trim={5cm 4.7cm 4.3cm 4.6cm}, clip]{images/retinafocus_iou_75_lower}} 
        \subfigure[]{\includegraphics[width=0.32\textwidth, trim={5cm 4.7cm 4.3cm 4.6cm}, clip]{images/retinafocus_iou_90_lower}} 
        \caption{Tỷ lệ các kích thước của bounding box \index{bounding box} mà RetinaFace không dự đoán ra tương ứng với IoU \index{IoU} 0.5 (a), IoU \index{IoU} 0.75 (b), IoU \index{IoU} 0.9 (c)}
        \label{fig:retinafocus_iou_lower}
    \end{figure}

    \noindent
    Cụ thể hơn, trong hình \ref{fig:retinafocus_iou_lower}, dù xét ở mức IoU \index{IoU} nào, thì các bounding box \index{bounding box} có kích thước nhỏ từ 0 đến 60 đều chiếm tổng tỷ lệ lớn, cụ thể ... đối với IoU \index{IoU} 0.5, ... đối với IoU \index{IoU} 0.75 và ... đối với IoU \index{IoU} 0.9.

    \noindent
    Hơn nữa, với kiến trúc của FPN như hình \ref{fig:retinafocus_architecture}, một bounding box \index{bounding box} có kích thước $4 \times 4$ ở ảnh đầu vào sẽ có tương ứng một khu vực có kích thước $2 \times 2$ ở feature maps \index{feature maps} ${C}_{2}$ và ${P}_{2}$, $1 \times 1$ ở feature maps \index{feature maps} ${C}_{3}$ và ${P}_{3}$ và gần như không còn thông tin ở các feature maps \index{feature maps} từ ${C}_{4}$ và ${P}_{4}$ trở đi.
    Điều này khiến cho các bounding box \index{bounding box} này trở thành các điểm dữ liệu nhiễu của Nhánh Focus \index{nhánh Focus}, khiến cho việc học của Nhánh Focus \index{nhánh Focus} bị giảm hiệu quả.

    \noindent
    Từ những phân tích trên, chúng tôi lựa chọn lần lượt các tham số $a = 5, b = 60, c = 150$ tương ứng với groundtruth \index{groundtruth} bounding box \index{bounding box} có kích thước từ $5 \times 5$ đến $60 \times 60$ là các bounding box \index{bounding box} cần được focus, các groundtruth \index{groundtruth} bounding box \index{bounding box} có kích thước dưới $5 \times 5$ hoặc từ $60 \times 60$ đến $150 \times 150$ là các bounding box \index{bounding box} không cần quan tâm và các groundtruth \index{groundtruth} bounding box \index{bounding box} có kích thước trên $150 \times 150$ là các bounding box \index{bounding box} được coi như là background \index{background}.

    \noindent
    \textbf{\textit{Thuật toán sinh Focus Chips}} \\
    Dựa trên AutoFocus \cite{najibi2019autofocus}, sau khi mô hình đã được huấn luyện và dự đoán ra được pixels \index{pixels} cần được focus, mô hình cần một thuật toán để crop ra được khu vực cần focus trên ảnh làm đầu vào cho cả hai nhánh Detection \index{nhánh Detection} và nhánh Focus \index{nhánh Focus} ở nhữnglượt tiếp theo.
    Và đó là vai trò của thuật toán sinh Focus Chips.

    \begin{figure}[H]
        \centering
        \includegraphics[width=10cm] {images/autofocus_focus_chip_gen}
        \caption{Chi tiết thuật toán sinh Focus Chips (Nguồn: \cite{najibi2019autofocus})}
        \label{fig:autofocus_focus_chip_gen}
    \end{figure}

    \noindent
    Trong quá trình dự đoán, sau khi mô hình đã dự đoán được các pixels \index{pixels} cần được focus (ký hiệu là $\mathcal{P}$) trên Focus Pixel  mask, ta biến đổi mask này trở về dạng binary mask bằng threshold $t$.
    Tham số $t$ được sử dụng để cân đối giữa tốc độ và độ chính xác của mô hình (cụ thể với tham số $t$ lớn, số lượng các pixels \index{pixels} cần được focus sẽ giảm đi và tốc độ của mô hình AutoFocus sẽ tăng và ngược lại). \\
    Từ binary mask đã được sinh ra ở trên, thuật toán sinh Focus Chips sẽ đưa qua một filter có kích thước $d \times d$ nhằm giãn nở các pixels \index{pixels} thêm một chút để thu được các thành phần liên thông $\mathcal{S}$, từ đó có nhiều thông tin hơn khi crop ảnh đầu vào với các focus pixels \index{pixels} này. \\
    Cuối cùng, ta crop ra các chip $\mathcal{C}$ với kích thước tối thiểu là $k \times k$ và bao trọn các thành phần liên thông $\mathcal{S}$ trên.
    Các chip trong $\mathcal{C}$ nếu có overlap với nhau sẽ được gộp lại chung thành một chip. \\
    Việc sinh ra các chip $\mathcal{C}$ giúp mô hình AutoFocus có thể sử dụng ý tưởng Image Pyramids nhưng tiết kiệm chi phí tính toán nhờ loại bỏ các khu vực khả năng cao không chứa đối tượng.

    \noindent
    \textbf{\textit{Thuật toán Focus Stacking}} \\
    Một vấn đề cần phải giải quyết khi thực hiện dự đoán với ý tưởng Image Pyramids trong bài toán nhận diện đối tượng \index{nhận diện đối tượng} là việc tổng hợp lại các bounding box \index{bounding box}.
    Với ý tưởng từ AutoFocus \cite{najibi2019autofocus}, vấn đề này còn phức tạp hơn với trường hợp một đối tượng có kích thước lớn được dự đoán ở kích thước này, nhưng đến kích thước tiếp theo, đối tượng đó bị crop trong quá trình crop chip và trở thành một đối tượng có kích thước nhỏ hơn.
    Nhằm hạn chế bớt vấn đề này, nhóm tác giả chỉ ra rằng \textit{bước 2} trong thuật toán sinh Focus Chips \ref{fig:autofocus_focus_chip_gen} là cực kỳ quan trọng.

    \begin{figure}[H]
        \centering
        \includegraphics[width=10cm] {images/autofocus_focus_stack}
        \caption{Ví dụ về cơ chế hoạt động của thuật toán Focus Stacking (Nguồn: \cite{najibi2019autofocus})}
        \label{fig:autofocus_focus_stack}
    \end{figure}

    \noindent
    Tuy nhiên, nhóm tác giả cũng đề ra một số luật nhằm loại bỏ các dự đoán lỗi của các đối tượng được định vị trên một focus chip: \\
    - Nếu một đối tượng nằm trên một biên của chip nhưng không phải biên của ảnh đầu vào (nghĩa là đối tượng này đã bị crop sau khi qua thuật toán sinh Focus Chip), thì dự đoán sẽ bị loại bỏ. \\
    - Nếu một đối tượng nằm trên một biên của chip và đó là biên của ảnh đầu vào, nhóm tác giả sẽ tiếp tục kiểm tra biên còn lại của đối tượng, nếu đó là biên của chip, dự đoán sẽ bị loại, còn nếu đó không phải là biên của chip, dự đoán sẽ được giữ lại. \\
    - Nếu một đối tượng nằm trên hai biên của chip và đó đều là hai biên của ảnh đầu vào, nhóm tác giả sẽ giữ lại những dự đoán này. \\
    Sau khi loại bỏ bớt các dự đoán bằng thuật toán Focus Stacking, mô hình AutoFocus đưa ra tổng hợp dự đoán từ các kích thước ảnh khác nhau và là các dự đoán cuối cùng của ảnh đầu vào.
}