\def\fasterrcnn{
    \subsubsection{Mô hình Faster R-CNN}
    Được lấy động lực từ những điểm yếu của mô hình Fast R-CNN, nhóm tác giả đã nghiên cứu và phát triển mô hình Faster R-CNN \cite{ren2015faster} với trung tâm là kiến trúc mô hình Region Proposal Network (gọi tắt là RPN).
    Mô hình Region Proposal Network được kỳ vọng sẽ thay thế hoàn toàn các thuật toán như Selective Search trong thành phần Region proposals module của các mô hình two-stage giải quyết bài toán object detection.
    Việc thay thế các thuật toán bằng một kiến trúc deep learning hướng đến việc cải thiện không chỉ tốc độ của mô hình mà còn cải thiện về độ chính xác.

    \noindent
    \textbf{\textit{Kiến trúc mô hình Region Proposal Network}} \\
    Mô hình RPN nhận đầu vào là ảnh với kích thước bất kỳ và trả đầu ra là toạ độ của các khu vực và xác suất khu vực đó là đối tượng nào trong các lớp đối tượng.
    Nhằm tiết kiệm chi phí tính toán, mô hình RPN dùng chung phần Feature extraction module với Fast R-CNN.

    \begin{figure}[H]
        \centering
        \includegraphics[width=9cm] {images/faster_rcnn_rpn}
        \caption{Kiến trúc mô hình Region Proposal Network (Nguồn: \cite{ren2015faster})}
        \label{fig:faster_rcnn_rpn}
    \end{figure}
    
    \noindent
    Sau khi đưa ảnh qua Feature extraction module và thu được một feature maps, mô hình RPN nhận đầu vào là feature maps này và trả đầu ra là các khu vực đề xuất gọi là các anchor.
    Nhóm tác giả xây dựng phương pháp đề xuất các anchor dựa trên kích thước và tỷ lệ giữa chiều dài và chiều rộng của anchor.
    Cụ thể, mô hình RPN đưa feature maps qua một lớp Conv và thu được một feature maps mới có kích thước $W x H$.
    Từ đó, nhóm tác giả đề xuất ba kích thước của anchor và ba tỷ lệ giữa chiều dài và chiều rộng của anchor tạo ra chín anchor với mỗi pixel trên feature maps kích thước $W x H$.
    Tổng cộng trên toàn bộ feature maps kích thước $W x H$, ta thu được $W x H x 9$ anchor.
    Các feature maps đại diện cho các anchor này được tiếp tục đưa qua các lớp Conv để biến đổi về các feature maps mới có dạng $(W x H x 9) x 1$ đại diện cho xác suất anchor đó là object và có dạng $(W x H x 9) x 4$ đại diện cho 4 toạ độ x của góc trái trên, y của góc trái trên, chiều dài và chiều rộng của bounding box.

    \noindent
    Một điểm mạnh của RPN so với các mô hình object detection thời bấy giờ đó chính là khả năng dự đoán được các object có kích thước khác nhau và tỷ lệ giữa chiều dài và chiều rộng khác nhau nhờ vào cách cấu hình của anchor.

    \begin{figure}[H]
        \centering
        \includegraphics[width=15cm] {images/faster_rcnn_multi_scale_anchor}
        \caption{So sánh các kiến trúc xử lý vấn đề object có kích thước khác nhau và tỷ lệ giữa chiều dài và chiều rộng khác nhau (Nguồn: \cite{ren2015faster})}
        \label{fig:faster_rcnn_multi_scale_anchor}
    \end{figure}

    \noindent
    Một số kiến trúc đã được đề xuất ở thời điểm đó nhưng đều gặp phải rào cản về khối lượng tính toán lớn. \\
    - Kiến trúc đầu tiên là \textit{image/feature pyramids} sử dụng ảnh với nhiều kích thước khác nhau nhằm tạo ra feature maps có nhiều kích thước khác nhau.
    Kiến trúc này tốn rất nhiều chi phí tính toán do ta cần xử lý nhiều lần (thường là ba lần) với mỗi ảnh đầu vào khác nhau. \\
    - Kiến trúc thứ hai là \textit{pyramid of filters} đưa cùng một feature maps đầu vào qua nhiều khối Conv có kích thước của kernel khác nhau (thường là Conv với kernel 5x7 và Conv với kernel 7x5).
    Kiến trúc này tiết kiệm chi phí tính toán hơn một chút so với kiến trúc đầu tiên và thường được sử dụng kết hợp cùng với kiến trúc đầu tiên. \\
    - Kiến trúc cuối cùng là \textit{pyramid of anchors} được đề xuất trong RPN sử dụng nhiều anchor với các kích thước khác nhau và tỷ lệ giữa chiều dài và chiều rộng khác nhau.
    Kiến trúc này chỉ tăng một lượng nhỏ chi phí tính toán nếu ta tăng số lượng anchor, còn phần chi phí tính toán đối với feature maps vẫn được giữ nguyên. \\
    Phần cải tiến của RPN đối với object có kích thước khác nhau và tỷ lệ giữa chiều dài và chiều rộng khác nhau chỉ là những cải tiến tại thời điểm đó mà thôi.
    Ở \textit{phần 2.2. Kiến trúc Feature Pyramid Networks}, ta sẽ nghiên cứu một mô hình nâng cấp hơn của Faster R-CNN, giải quyết một cách triệt để hơn vấn đề này.

    \noindent
    \textbf{\textit{Hàm loss và cách train mô hình RPN}} \\
    Để train được mô hình RPN, nhóm tác giả gán cho mỗi anchor một lớp groundtruth và thiết lập hàm loss đối với từng anchor.
    Nhóm tác giả gán lớp groundtruth positive cho anchor dựa theo hai cách sau: \\
    - Những anchor có chỉ số IoU lớn nhất đối với một groundtruth bounding box được gán là anchor positive. \\
    - Những anchor có chỉ số IoU lớn hơn 0.7 đối với một groundtruth bounding box được gán là anchor positive. \\
    Với hai cách như trên, một groundtruth bounding box có thể gán được cho nhiều anchor khác nhau.
    Ngoài ra, nhóm tác giả cũng gán lớp groundtruth negative cho các anchor không phải là positive và có chỉ số IoU nhỏ hơn 0.3 đối với một groundtruth bounding box. \\
    Từ đó, mô hình Faster R-CNN tối ưu hàm loss sau:

    \begin{equation}
        \label{eq:faster_rcnn_loss}
        L(\{p_i\}, \{t_i\}) = \frac{1}{N_{cls}}\sum_i L_{cls}(p_i, p^{*}_i) + \lambda\frac{1}{N_{reg}}\sum_i  p^{*}_i L_{reg}(t_i, t^{*}_i).
    \end{equation}

    \noindent
    trong đó: \\
    - \textit{i} là chỉ số của từng anchor. \\
    - \textit{$p_i$} là xác suất mà anchor chứa đối tượng. \\
    - \textit{$p^{*}_i$} là groundtruth của anchor (là 1 nếu anchor đó được gán là chứa đối tượng, là 0 nếu anchor đó được gán là không chứa đối tượng). \\
    - \textit{$t_i$} là vector gồm 4 giá trị đại diện cho toạ độ của khu vực mà mô hình RPN đề xuất. \\
    - \textit{$t^{*}_i$} là vector gồm 4 giá trị đại diện cho toạ độ của groundtruth bounding box tương ứng với anchor đó. \\
    Hàm loss trên gồm các thành phần: \\
    - \textit{$L_{cls}$}: là hàm loss phân lớp thông thường giúp xác định anchor có chứa đối tượng hay không. \\
    - \textit{$L_{reg}$}: là hàm loss hồi quy đối với các anchor positive, giúp tinh chỉnh toạ độ của khu vực mà mô hình đề xuất.
    Cụ thể, nhóm tác giả sử dụng $L_{reg}(t_i, t^{*}_i)=L_1(t_i - t^{*}_i)$ giống với hàm loss sử dụng trong mô hình Fast R-CNN \cite{girshick2015fast}.

    \noindent
    Mô hình RPN được thiết kế để có thể train cùng với quá trình train object detection từ đó giúp kết quả đề xuất khu vực trở nên chính xác hơn.
    Tuy nhiên, có một vấn đề nảy sinh khi sử dụng mô hình RPN cho việc đề xuất khu vực, đó là mô hình sẽ đề xuất ra nhiều các anchor negative hơn rất nhiều so với số anchor positive.
    Việc train mô hình trên từng anchor kết hợp với hiện tượng trên sẽ khiến cho tổng quan mô hình object detection bị mất cân bằng dữ liệu.
    Ngoài ra, việc train mô hình với toàn bộ số anchor được đề xuất ra cũng sẽ khiến cho khối lượng tính toán lớn và thời gian kéo dài quá trình train mô hình.
    Từ đó, nhóm tác giả đề xuất việc lựa chọn ngẫu nhiên 256 anchor trên mỗi ảnh để thực hiện việc tính loss. Việc lựa chọn này giúp tỷ lệ anchor positive và negative trở nên cân bằng hơn và giảm thiểu bởi những phần khối lượng tính toán dư thừa.

    \noindent
    \textbf{\textit{Sự kết hợp giữa mô hình Region Proposal Network và Fast R-CNN}} \\
    Nhóm tác giả cho rằng, việc train mô hình RPN và Fast R-CNN cần phải diễn ra đồng thời, vì từ đó, việc chia sẻ chung thành phần backbone Conv mới trở nên hiệu quả.

    \begin{figure}[H]
        \centering
        \includegraphics[width=10cm] {images/faster_rcnn_model}
        \caption{Toàn cảnh sự kết hợp của mô hình Region Proposal Network và Fast R-CNN tạo ra mô hình Faster R-CNN (Nguồn: \cite{ren2015faster})}
        \label{fig:faster_model}
    \end{figure}

    \noindent
    Nhóm tác giả nêu ra ba phương án để train mô hình RPN kết hợp với Fast R-CNN: \\
    - Cách 1: \textit{Alternating training}: Nhóm tác giả train mô hình RPN trước sử dụng những hàm loss của RPN nói trên.
    Sau khi train xong mô hình RPN, tác giả sử dụng những khu vực được đề xuất bởi RPN để train mô hình Fast R-CNN.
    Mô hình backbone sau khi được train bởi Fast R-CNN tiếp tục được sử dụng để train mô hình RPN mới và vòng lặp này tiếp tục diễn ra cho đến khi kết quả của mô hình hội tụ. \\
    - Cách 2: \textit{Approximate joint training}: Phương pháp này kết hợp RPN và Fast R-CNN thành một mô hình duy nhất trong quá trình train.
    Các khu vực được đề xuất bởi RPN được coi như là tất định đối với nhánh Fast R-CNN và khiến cho phương pháp train này được gọi là \textit{approximate} bởi vì những thông tin từ nhánh Fast R-CNN sẽ không được cập nhật cho nhánh RPN.
    Quá trình backprop được thực hiện độc lập giữa RPN và Fast R-CNN, riêng phần backbone chung của RPN và Fast R-CNN được cập nhật theo giá trị hàm loss của cả RPN và Fast R-CNN.
    Phương pháp này đạt hiệu quả thấp hơn chút so với \textit{Alternating training} tuy nhiên thời gian train được giảm 25 - 50\%.
    - Cách 3: \textit{Non-approximate joint training}: Phương pháp này cải thiện được vấn đề \textit{approximate} tồn đọng của \textit{Approximate joint training}.
    Tuy nhiên, để làm được điều này, nhóm tác giả cần tinh chỉnh lại lớp RoI pooling trong Fast R-CNN để có thể update cho cả các thành phần của mô hình Fast R-CNN và RPN.
    Điều này nằm ngoài nội dung của nghiên cứu này nên nhóm tác giả không đề cập kỹ hơn.

    \noindent
    Tóm lại, nhóm tác giả dựa vào phương pháp \textit{Alternating training} và thực hiện quá trình train gồm 4 bước như sau: \\
    - Bước 1: Nhóm tác giả khởi tạo mô hình RPN với pretrained ImageNet và train mô hình RPN. \\
    - Bước 2: Nhóm tác giả khởi tạo mô hình Fast R-CNN với pretrained ImageNet và train mô hình Fast R-CNN với các khu vực được đề xuất bởi RPN. \\
    - Bước 3: Nhóm tác giả khởi tạo lại mô hình RPN nhưng sử dụng phần backbone đã được train từ bước 2.
    Nhóm tác giả chỉ train những lớp riêng của mô hình RPN và không cập nhật cho phần backbone. \\
    - Bước 4: Nhóm tác giả finetune lại những lớp riêng của mô hình Fast R-CNN với các khu vực được đề xuất bởi RPN và thu được mô hình Faster R-CNN cuối cùng. \\
    Nhóm tác giả cũng đã lặp lại 4 bước trên vài lần nhưng kết quả không thay đổi quá nhiều.

    \noindent
    \textbf{\textit{Kết quả của mô hình Faster R-CNN}} \\

}